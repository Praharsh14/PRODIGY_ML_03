# PRODIGY_ML_03
Classifiaction of two objects using support vector machine 
Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. Its primary objective is to find a hyperplane that best separates the data points into different classes. The hyperplane is chosen in such a way that it maximizes the margin, which is the distance between the hyperplane and the nearest data points of each class.

Here are some key concepts related to SVM:

Hyperplane: In a two-dimensional space, a hyperplane is a line that separates the data into two classes. In higher dimensions, it becomes a plane or a hyperplane.

Support Vectors: These are the data points that are closest to the hyperplane and play a crucial role in determining the optimal hyperplane.

Margin: The margin is the distance between the hyperplane and the nearest data point from either class. SVM aims to maximize this margin.

Kernel Trick: SVM can handle non-linear decision boundaries by mapping the input features into a higher-dimensional space using a kernel function. This allows SVM to find a linear decision boundary in the transformed space.

C parameter: It is a regularization parameter that controls the trade-off between having a smooth decision boundary and classifying the training points correctly.

SVM can be used for both classification and regression tasks. In classification, it works well for binary and multiclass problems. 
In regression, the objective is to fit a hyperplane to predict continuous values.
